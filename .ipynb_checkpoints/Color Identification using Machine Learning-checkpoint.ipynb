{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Identification using Machine Learning\n",
    "\n",
    "In this notebook, I have used machine learning algorithm, `KMeans`, to extract colors from a give image. I will use `OpenCV2` for image manipulation, apply `KMeans` to identify the major colors and then plot the information using `Matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Let's first import necessary libraries. We need `sklearn` for KMeans algorithm, `matplotlib.pyplot` for plotting graphs, `numpy` to work with arrays, `cv2` to work with image data, `collections` to use Counter to count values, `rgb2lab` to convert RGB values and `deltaE_cie76` to calculate similarity between colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from skimage.color import rgb2lab, deltaE_cie76\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with OpenCV\n",
    "\n",
    "Let's first read a sample image and understand basic operations that we can do on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('sample_image.jpg')\n",
    "print(\"The type of this input is {}\".format(type(image)))\n",
    "print(\"Shape: {}\".format(image.shape))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the image has different colors as compared to the original image. This is because by default OpenCV reads the images in the color order `BLUE GREEN RED` i.e. BGR. Thus, we need to convert it into `REG GREEN BLUE` i.e. RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image can also be converted to grayscale if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to resize the image to a certain size whenever the images are huge or when we are working with multiple images of different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = cv2.resize(image, (1200, 600))\n",
    "plt.imshow(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Identification\n",
    "\n",
    "Not that we know a bit about OpenCV, let's start identifying colors from an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define a function that can give us the `hex` values of our the colors that we will identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2HEX(color):\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans expects flattened array as input during its fit method. Thus, we need to reshape the image using numpy. Then, we can apply KMeans to first fit and then predict on the image to get the results. Then, the cluster colors are identified an arranged in the correct order. We plot the colors as a pie chart.\n",
    "\n",
    "I have combined all the steps in two method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(image, number_of_colors, show_chart):\n",
    "    \n",
    "    modified_image = cv2.resize(image, (600, 400), interpolation = cv2.INTER_AREA)\n",
    "    modified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)\n",
    "    \n",
    "    clf = KMeans(n_clusters = number_of_colors)\n",
    "    labels = clf.fit_predict(modified_image)\n",
    "    \n",
    "    counts = Counter(labels)\n",
    "    # sort to ensure correct color percentage\n",
    "    counts = dict(sorted(counts.items()))\n",
    "    \n",
    "    center_colors = clf.cluster_centers_\n",
    "    # We get ordered colors by iterating through the keys\n",
    "    ordered_colors = [center_colors[i] for i in counts.keys()]\n",
    "    hex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\n",
    "    rgb_colors = [ordered_colors[i] for i in counts.keys()]\n",
    "\n",
    "    if (show_chart):\n",
    "        plt.figure(figsize = (8, 6))\n",
    "        plt.pie(counts.values(), labels = hex_colors, colors = hex_colors)\n",
    "    \n",
    "    return rgb_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_colors(get_image('sample_image.jpg'), 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search images using Color\n",
    "\n",
    "From the model above, we can extract the major colors. \n",
    "This create the opportunity to search for images based on certain colors. We can select a color and if it's hex matches or is close to the hex of the major colors of the image, we say it's a match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get all the images and store them in the `images` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIRECTORY = 'images/cl2'\n",
    "COLORS = {\n",
    "    'GREEN': [0, 128, 0],\n",
    "    'BLUE': [0, 0, 128],\n",
    "    'YELLOW': [255, 255, 0]\n",
    "}\n",
    "images = []\n",
    "\n",
    "for file in os.listdir(IMAGE_DIRECTORY):\n",
    "    if not file.startswith('.'):\n",
    "        images.append(get_image(os.path.join(IMAGE_DIRECTORY, file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, len(images), i+1)\n",
    "    plt.imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the function below. We will try to match with the top 10 colors of the image. It is highly possible that there will be no extact match for the hex codes, thus we calculate the similarity between the chosen color and the colors of the image. \n",
    "\n",
    "We keep a threshold value such that if the difference between the chosen color and any of the selected colors is less than that threshold, we declare it as a match.\n",
    "\n",
    "Hex values or RGB values cannot be directly compared so we first convert them to a device independant and color uniform space. We use `rgb2lab` to convert the values and then find the difference using `deltaE_cie76`. The method calculates the difference between all top 5 colors of the image and the selected color and if atleast one is below the threshold, we show the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_image_by_color(image, color, threshold = 60, number_of_colors = 10): \n",
    "    \n",
    "    image_colors = get_colors(image, number_of_colors, False)\n",
    "    selected_color = rgb2lab(np.uint8(np.asarray([[color]])))\n",
    "\n",
    "    select_image = False\n",
    "    for i in range(number_of_colors):\n",
    "        curr_color = rgb2lab(np.uint8(np.asarray([[image_colors[i]]])))\n",
    "        diff = deltaE_cie76(selected_color, curr_color)\n",
    "        if (diff < threshold):\n",
    "            select_image = True\n",
    "    \n",
    "    return select_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the above method for all the images in our set and show relevant images out of the same that approximately match our selected color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_selected_images(images, color, threshold, colors_to_match):\n",
    "    index = 1\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        selected = match_image_by_color(images[i],\n",
    "                                        color,\n",
    "                                        threshold,\n",
    "                                        colors_to_match)\n",
    "        if (selected):\n",
    "            plt.subplot(1, len(images), index)\n",
    "            plt.imshow(images[i])\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for GREEN\n",
    "plt.figure(figsize = (20, 10))\n",
    "show_selected_images(images, [255,255,255], 60, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for GREEN\n",
    "plt.figure(figsize = (20, 10))\n",
    "show_selected_images(images, COLORS['GREEN'], 60, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for BLUE\n",
    "plt.figure(figsize = (20, 10))\n",
    "show_selected_images(images, COLORS['BLUE'], 60, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for YELLOW\n",
    "plt.figure(figsize = (20, 10))\n",
    "show_selected_images(images, COLORS['YELLOW'], 60, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we used KMeans to extract majority colors from images. We then used the RGB Values of Colors to identify images from a collection that have that color in them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
